{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anastaszi/GenAI/blob/main/LangChain_Agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "985ce054",
      "metadata": {
        "id": "985ce054"
      },
      "source": [
        "# LangChain Agents\n",
        "\n",
        "We've referenced `LangChain` several times throughout this course, this notebook dives deeper into the `Agents` component of the library. We've already discussed the concept of `chains` and how they can be used to architect complex LLM pipelines by chaining multiple models together. However, since these models are incredible flexible in what they can do (classifiction, text generation, code generation, etc.) we can integrate them with other systems - for example we have have a model generate the code to make an API call, write and execute Data Science code, query tabular data, the list goes on. We can use `Agents` to interact with all these external systems to exeucte actions dictated by LLMs. The fundamental idea of an `Agent` is to let the LLM choose an action or sequence of actions to take give a various set of tools.\n",
        "\n",
        "\n",
        "This is a pretty general description, let's take a look at some of the specifics via code:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "720064df",
      "metadata": {
        "id": "720064df"
      },
      "source": [
        "We'll be using an OpenAI model for this example. Let's first use the `OpenAI` module to instantiate the `llm` object:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7043989e",
      "metadata": {
        "id": "7043989e",
        "outputId": "9262e25a-dd94-46f9-8806-c4ca60d9047c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "········\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "OPENAI_API_KEY = getpass()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9a852e8",
      "metadata": {
        "id": "c9a852e8"
      },
      "outputs": [],
      "source": [
        "from langchain import OpenAI\n",
        "\n",
        "llm = OpenAI(\n",
        "    openai_api_key=OPENAI_API_KEY,\n",
        "    temperature=0,\n",
        "    model_name=\"text-davinci-003\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca210079",
      "metadata": {
        "id": "ca210079"
      },
      "source": [
        "As stated eariler, `Agents` are all about letting LLMs pick the best tool to solve the problem, as part of these agents, we'll need to a include a tool or list of tools for the LLM to choose from to exeucte it's designated sequence of events. Within `LangChain` there are a variety of tools that can be used as part of these `Agents`. In this simple example we'll use the calculator tool called `llm-math`, but you can take a look at a comprehensive built-in list of tools [here](https://github.com/langchain-ai/langchain/tree/master/libs/langchain/langchain/tools)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cf331cb",
      "metadata": {
        "id": "2cf331cb"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import load_tools\n",
        "\n",
        "tools = load_tools(\n",
        "    ['llm-math'],\n",
        "    llm=llm\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b5a48cf",
      "metadata": {
        "id": "0b5a48cf"
      },
      "source": [
        "Alternatively, the user has the option to creat their own tools - if we were to create this calculator tool from scratch, it would look something like the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "493ed421",
      "metadata": {
        "id": "493ed421"
      },
      "outputs": [],
      "source": [
        "# Create a calculator tool\n",
        "from langchain.chains import LLMMathChain\n",
        "from langchain.agents import Tool\n",
        "\n",
        "llm_math = LLMMathChain(llm=llm)\n",
        "\n",
        "# initialize the math tool\n",
        "math_tool = Tool(\n",
        "    name='Calculator',\n",
        "    func=llm_math.run,\n",
        "    description='A tools that should be used exclusively for mathematical computation'\n",
        ")\n",
        "# when giving tools to LLM, we must pass as list of tools\n",
        "tools = [math_tool]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5142567",
      "metadata": {
        "id": "b5142567"
      },
      "source": [
        "Great! We now have a tool, but just a tool isn't too much use to us - we need an `Agent`! As of July 2023, there are a few different agent types in `LangChain`:\n",
        "\n",
        "- `Zero-shot ReAct`\n",
        "    - Use ReAct framework to determine the proper tool. This decision is purely done based on the tools description. Since the tool decision is decided by the description, all tools using this agent must have a description. This is the most general purpose action agent\n",
        "- `Structured input ReAct`\n",
        "    - This agent is capable of using multi-input tools. Unlike older tools, this one can use usea a tools' argument schema to create a structured action input. This agent can be really usefl for complex tool usage.\n",
        "- `OpenAI Functions`\n",
        "    - Certain OpenAI models have been specifically been fine tuned to detect when a function should be called and respon with the inputs that should be passed to the function. These are modesl like gpt-3.5-turbo-0613 and gpt-4-0613. This agent is designed for these specific models and should be used accordingly.\n",
        "- `Conversational`\n",
        "    - As it's name states, this agent is built to be used in conversational settings. This agent uses a prompt that's specifically designted for the conversational, text-generation use case. Simialar to above, it uses the ReAct framwork to decide on the tool, and uses memory to remember the previous conversation interactions.\n",
        "- `Self ask with search`\n",
        "    - This agent uses a tool that must be name `Intermediate Answer`. The tool should be one that looks up *factual* answers to questions. This agent is the equivalent to the agent laid out in [this](https://ofir.io/self-ask.pdf) paper.\n",
        "- `ReAct document store`\n",
        "    - Similar to `Zero-shot ReAct` this leverages the ReAct framework against a document store\n",
        "- ` Plan-and-execute agents`\n",
        "    - Plan and execute agents accomplish an objective by first planning what to do, then executing the sub tasks. You can read more about the implementation in [this](https://arxiv.org/abs/2305.04091) paper."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29eca18e",
      "metadata": {
        "id": "29eca18e"
      },
      "source": [
        "In order to work with an `Agent` we'll need to define three things:\n",
        "1. A large language model that will make the decision on path forward given the toolset\n",
        "2. Tool or tools for the llm to interact with\n",
        "3. An agent to control the interaction pattern between the llm and the tool(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3db1a1a2",
      "metadata": {
        "id": "3db1a1a2"
      },
      "source": [
        "For this agent, since it's a simple math problem, we'll use the `Zero-shot ReAct` agent. We'll initialize the object by specifying the `agent` type, `tools`, `llm`, `verbosity` (so we can easily see what's going on underneath the hood), and the `max_iterations`.\n",
        "\n",
        "When interacting with agents it is really important to set the `max_iterations` parameters because agents can get stuck in infinite loops that consume plenty of tokens. The default value is 15 to allow for many tools and complex reasoning but for most applications you should keep it much lower."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b25bb4c7",
      "metadata": {
        "id": "b25bb4c7"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import initialize_agent\n",
        "\n",
        "zero_shot_agent = initialize_agent(\n",
        "    agent=\"zero-shot-react-description\",\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    max_iterations=3\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03e824cb",
      "metadata": {
        "id": "03e824cb"
      },
      "source": [
        "Let's test the agent!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b0e0d19",
      "metadata": {
        "id": "8b0e0d19",
        "outputId": "28beaefe-6ccd-4635-a995-5f18bd751ae7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to calculate the power of a product\n",
            "Action: Calculator\n",
            "Action Input: 6.78*3.2^1.111\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAnswer: 24.686033827858196\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: 24.686033827858196\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'what is (6.78*3.2)^1.111?', 'output': '24.686033827858196'}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "zero_shot_agent(\"what is (6.78*3.2)^1.111?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43e6ec83",
      "metadata": {
        "id": "43e6ec83"
      },
      "source": [
        "Now that we have this simple agent up and running that can handle math computation, let's add some complexity. In the example below, we'll build an agent that can access the Google Search APIs to answer user queries. To do this, we'll first need to install some dependencies.\n",
        "\n",
        "\n",
        "\n",
        "*Below example adopted from [here](https://www.datasciencebyexample.com/2023/05/27/understanding-langchain-chains-and-agents/)*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a76bf0f6",
      "metadata": {
        "id": "a76bf0f6",
        "outputId": "c58c9179-0f2e-4562-b560-4d1babb6625c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: google-search-results in /Users/marymoesta/Library/Python/3.8/lib/python/site-packages (2.4.2)\n",
            "Requirement already satisfied: requests in /Users/marymoesta/Library/Python/3.8/lib/python/site-packages (from google-search-results) (2.28.1)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/marymoesta/Library/Python/3.8/lib/python/site-packages (from requests->google-search-results) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/marymoesta/Library/Python/3.8/lib/python/site-packages (from requests->google-search-results) (3.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/marymoesta/Library/Python/3.8/lib/python/site-packages (from requests->google-search-results) (1.26.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/marymoesta/Library/Python/3.8/lib/python/site-packages (from requests->google-search-results) (2022.6.15)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install google-search-results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd6eaa81",
      "metadata": {
        "id": "bd6eaa81"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
        "from langchain.prompts import BaseChatPromptTemplate\n",
        "from langchain import SerpAPIWrapper, LLMChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from typing import List, Union\n",
        "from langchain.schema import AgentAction, AgentFinish, HumanMessage\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9eeb0d12",
      "metadata": {
        "id": "9eeb0d12"
      },
      "source": [
        "For this example you'll need a Serp API key. You can create a SerpAPI account for free and generate a key [here](https://serpapi.com/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2a92cc6",
      "metadata": {
        "id": "b2a92cc6",
        "outputId": "8a93821e-6b63-48cf-c6ab-4bdc47de64d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "········\n"
          ]
        }
      ],
      "source": [
        "SERPAPI_API_KEY = getpass()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dad4f012",
      "metadata": {
        "id": "dad4f012"
      },
      "source": [
        "Once we've defined the Google Search API key, we'll instantiate the tool:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8299c285",
      "metadata": {
        "id": "8299c285"
      },
      "outputs": [],
      "source": [
        "# Define which tools the agent can use to answer user queries\n",
        "search = SerpAPIWrapper(serpapi_api_key=SERPAPI_API_KEY)\n",
        "tools = [\n",
        "    Tool(\n",
        "        name = \"Search\",\n",
        "        func=search.run,\n",
        "        description=\"useful for when you need to answer questions about current events\"\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8da231e3",
      "metadata": {
        "id": "8da231e3"
      },
      "source": [
        "Generate the prompt that we'll template later:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19d421a7",
      "metadata": {
        "id": "19d421a7"
      },
      "outputs": [],
      "source": [
        "# Set up the base template\n",
        "template = \"\"\"Complete the objective as best you can. You have access to the following tools:\n",
        "\n",
        "{tools}\n",
        "\n",
        "Use the following format:\n",
        "\n",
        "Question: the input question you must answer\n",
        "Thought: you should always think about what to do\n",
        "Action: the action to take, should be one of [{tool_names}]\n",
        "Action Input: the input to the action\n",
        "Observation: the result of the action\n",
        "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
        "Thought: I now know the final answer\n",
        "Final Answer: the final answer to the original input question\n",
        "\n",
        "These were previous tasks you completed:\n",
        "\n",
        "\n",
        "\n",
        "Begin!\n",
        "\n",
        "Question: {input}\n",
        "{agent_scratchpad}\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d4edcca",
      "metadata": {
        "id": "0d4edcca"
      },
      "source": [
        "With this prompt, we'll need to do some custom parsing to ensure messages are passed in properly. We'll use this `CustomPromptTemplate` class, which extends `LangChains` `BaseChatPromptTemplate`, to generate and format the prompt and accompanying messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50bab594",
      "metadata": {
        "id": "50bab594"
      },
      "outputs": [],
      "source": [
        "# Set up a prompt template\n",
        "class CustomPromptTemplate(BaseChatPromptTemplate):\n",
        "    # The template to use\n",
        "    template: str\n",
        "    # The list of tools available\n",
        "    tools: List[Tool]\n",
        "\n",
        "    def format_messages(self, **kwargs) -> str:\n",
        "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
        "        # Format them in a particular way\n",
        "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
        "        thoughts = \"\"\n",
        "        for action, observation in intermediate_steps:\n",
        "            thoughts += action.log\n",
        "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
        "        # Set the agent_scratchpad variable to that value\n",
        "        kwargs[\"agent_scratchpad\"] = thoughts\n",
        "        # Create a tools variable from the list of tools provided\n",
        "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
        "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
        "        formatted = self.template.format(**kwargs)\n",
        "        return [HumanMessage(content=formatted)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1ca2038",
      "metadata": {
        "id": "e1ca2038"
      },
      "source": [
        "Generate the prompt using the custom class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92787703",
      "metadata": {
        "id": "92787703"
      },
      "outputs": [],
      "source": [
        "prompt = CustomPromptTemplate(\n",
        "    template=template,\n",
        "    tools=tools,\n",
        "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
        "    # This includes the `intermediate_steps` variable because that is needed\n",
        "    input_variables=[\"input\", \"intermediate_steps\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3771f094",
      "metadata": {
        "id": "3771f094"
      },
      "source": [
        "Next we'll define a `CustomOutputParser`, which extends the `AgentOutputParser` class. This class is responsible for parsing the action and action input to feed to the downstream `AgentAction`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe0df8ff",
      "metadata": {
        "id": "fe0df8ff"
      },
      "outputs": [],
      "source": [
        "class CustomOutputParser(AgentOutputParser):\n",
        "\n",
        "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
        "        # Check if agent should finish\n",
        "        if \"Final Answer:\" in llm_output:\n",
        "            return AgentFinish(\n",
        "                # Return values is generally always a dictionary with a single `output` key\n",
        "                # It is not recommended to try anything else at the moment :)\n",
        "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
        "                log=llm_output,\n",
        "            )\n",
        "        # Parse out the action and action input\n",
        "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
        "        match = re.search(regex, llm_output, re.DOTALL)\n",
        "        if not match:\n",
        "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
        "        action = match.group(1).strip()\n",
        "        action_input = match.group(2)\n",
        "        # Return the action and action input\n",
        "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0ac5b7d",
      "metadata": {
        "id": "d0ac5b7d"
      },
      "source": [
        "Instantiate an instace of the class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06757595",
      "metadata": {
        "id": "06757595"
      },
      "outputs": [],
      "source": [
        "output_parser = CustomOutputParser()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eba66681",
      "metadata": {
        "id": "eba66681"
      },
      "source": [
        "Similar to other notebooks, we'll be using one of `OpenAI`'s chat models for this agent. In order to use this model, we'll need to pass a valid API key (via `getpass()`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea4b95d7",
      "metadata": {
        "id": "ea4b95d7",
        "outputId": "02c3eba7-1799-4c62-f26c-99e6636dc3ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "········\n"
          ]
        }
      ],
      "source": [
        "OPENAI_API_KEY = getpass()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ca5a961",
      "metadata": {
        "id": "6ca5a961"
      },
      "source": [
        "Create the LLM that we'll feed to the agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87985d74",
      "metadata": {
        "id": "87985d74"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef1f36bf",
      "metadata": {
        "id": "ef1f36bf"
      },
      "source": [
        "Chain together the LLM and the prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff2cacc8",
      "metadata": {
        "id": "ff2cacc8"
      },
      "outputs": [],
      "source": [
        "# LLM chain consisting of the LLM and a prompt\n",
        "llm_chain = LLMChain(llm=llm, prompt=prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91276d8f",
      "metadata": {
        "id": "91276d8f"
      },
      "source": [
        "Here we're using the `LLMSingleActionAgent` since it's the base class for and single action agent. Since this process only invovles a google search, we don't need to worry about multi-actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c4c43bb",
      "metadata": {
        "id": "9c4c43bb"
      },
      "outputs": [],
      "source": [
        "tool_names = [tool.name for tool in tools]\n",
        "agent = LLMSingleActionAgent(\n",
        "    llm_chain=llm_chain,\n",
        "    output_parser=output_parser,\n",
        "    stop=[\"\\nObservation:\"],\n",
        "    allowed_tools=tool_names\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdbb9a73",
      "metadata": {
        "id": "bdbb9a73"
      },
      "source": [
        "Invoke the agent and see what happens!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70c150e3",
      "metadata": {
        "id": "70c150e3",
        "outputId": "027a072d-bf58-428a-c810-481bd6d6836d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to find the location of the first stage of the Tour De France Femmes.\n",
            "Action: Search\n",
            "Action Input: \"Tour De France Femmes first stage location\"\u001b[0m\n",
            "\n",
            "Observation:\u001b[36;1m\u001b[1;3mClermont-Ferrand\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI now know the location of the first stage of the Tour De France Femmes.\n",
            "Final Answer: The first stage of the Tour De France Femmes is in Clermont-Ferrand.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'The first stage of the Tour De France Femmes is in Clermont-Ferrand.'"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)\n",
        "agent_executor.run(\"Where is the first stage of the Tour De France Femmes?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9531a8ff",
      "metadata": {
        "id": "9531a8ff"
      },
      "source": [
        "![tour_de_femmes](../images/tour_de_femmes.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6bb5b16",
      "metadata": {
        "id": "e6bb5b16"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}